{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc399bb0-abb4-4cb5-80e5-600f13f7cb37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.16.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.3)\n",
      "Requirement already satisfied: hummingbird-ml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.4.12)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (69.0.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnx) (3.20.2)\n",
      "Requirement already satisfied: onnxconverter-common>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from hummingbird-ml) (1.14.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from hummingbird-ml) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from hummingbird-ml) (1.6.0)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from hummingbird-ml) (6.1.1)\n",
      "Requirement already satisfied: dill in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from hummingbird-ml) (0.3.9)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxconverter-common>=1.6.0->hummingbird-ml) (24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->hummingbird-ml) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->hummingbird-ml) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required Python libraries\n",
    "try:\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"torch\", \"onnx\", \"numpy\", \"hummingbird-ml\"])\n",
    "except:\n",
    "    print(\"Ensure all dependencies are installed.\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from hummingbird.ml import convert\n",
    "import numpy as np\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf707640",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/chris-chris/mina-zkml/releases/latest/download/mina-zkml-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38bbdc16-6187-4be3-b76c-b1802326c7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model exported to logistic_regression.onnx\n"
     ]
    }
   ],
   "source": [
    "# here we create and (potentially train a model)\n",
    "# make sure you have the dependencies required here already installed\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# y = 1 * x_0 + 2 * x_1 + 3\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "reg = LogisticRegression().fit(X, y)\n",
    "reg.score(X, y)\n",
    "model = convert(reg, \"torch\", X[:1]).model\n",
    "onnx_path = \"logistic_regression.onnx\"\n",
    "\n",
    "# Export ONNX model\n",
    "\n",
    "# Input to the model\n",
    "shape = X.shape[1:]\n",
    "dummy_input = torch.rand(1, *shape, requires_grad=True)\n",
    "torch_out = circuit(dummy_input)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model, dummy_input, onnx_path,\n",
    "    input_names=[\"input\"], output_names=[\"output\"],\n",
    "    opset_version=13\n",
    ")\n",
    "\n",
    "torch.onnx.export(circuit,               # model being run\n",
    "                  # model input (or a tuple for multiple inputs)\n",
    "                  dummy_input,\n",
    "                  # where to save the model (can be a file or file-like object)\n",
    "                  onnx_path,\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names=['input'],   # the model's input names\n",
    "                  output_names=['output'],  # the model's output names\n",
    "                  dynamic_axes={'input': {0: 'batch_size'},    # variable length axes\n",
    "                                'output': {0: 'batch_size'}})\n",
    "\n",
    "print(f\"ONNX model exported to {onnx_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eab9dd6-951d-405e-a0d9-678556b142aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data saved to input.json\n"
     ]
    }
   ],
   "source": [
    "# Prepare input data for proof generation\n",
    "data_path = \"input.json\"\n",
    "sample_input = X[:1]  # Use one sample from the dataset\n",
    "input_data = sample_input.flatten().tolist()  # Flatten for JSON serialization\n",
    "\n",
    "# Save the input data to a JSON file\n",
    "data = [input_data]  # Wrap in outer array [[]]\n",
    "with open(data_path, \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "print(f\"Input data saved to {data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8615a3-59db-4dc0-9939-fb4c43cebe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: Node { id: 0, name: \"input\", inputs: [], op: TypedSource { fact: 1,2,F32 }, outputs: [1,2,F32 >2/0] }\n",
      "Found Input operation\n",
      "Node: Node { id: 1, name: \"_operators.0.coefficients.0\", inputs: [], op: Const(2,4,F32 -0.2899942, -0.41289154, 0.4130071, 0.28987864, -0.6468678, 0.06529999, -0.06524275, 0.6468106), outputs: [2,4,F32 -0.2899942, -0.41289154, 0.4130071, 0.28987864, -0.6468678, 0.06529999, -0.06524275, 0.6468106 >2/1] }\n",
      "Found Const operation\n",
      "Node: Node { id: 2, name: \"/_operators.0/Gemm.ab\", inputs: [0/0>, 1/0>], op: EinSum mk,kn->mn (F32), outputs: [1,4,F32 >4/0] }\n",
      "Found matrix operation: EinSum\n",
      "Node: Node { id: 3, name: \"/_operators.0/Gemm.c_add_axis_1\", inputs: [], op: Const(1,4,F32 1.6625432, 0.5548876, -0.42277858, -1.7946522), outputs: [1,4,F32 1.6625432, 0.5548876, -0.42277858, -1.7946522 >4/1] }\n",
      "Found Const operation\n",
      "Node: Node { id: 4, name: \"/_operators.0/Gemm\", inputs: [2/0>, 3/0>], op: TypedBinOp(Add, None), outputs: [1,4,F32 >5/0 >9/0] }\n",
      "Found Add operation: Add\n",
      "Node: Node { id: 5, name: \"/_operators.0/ArgMax\", inputs: [4/0>], op: Reduce { axes: [1], reducer: ArgMax(false) }, outputs: [1,1,I64 >6/0] }\n",
      "Found ArgMax operation\n",
      "Node: Node { id: 6, name: \"/_operators.0/ArgMax-dispose-dims-1\", inputs: [5/0>], op: Rm(1), outputs: [1,I64 >8/1] }\n",
      "Found RmAxis operation\n",
      "Node: Node { id: 7, name: \"_operators.0.classes.0\", inputs: [], op: Const(4,I32 6, 8, 9, 11), outputs: [4,I32 6, 8, 9, 11 >8/0] }\n",
      "Found Const operation\n",
      "Node: Node { id: 8, name: \"/_operators.0/Gather\", inputs: [7/0>, 6/0>], op: Gather { axis: 0 }, outputs: [1,I32 ] }\n",
      "Found Gather operation\n",
      "Node: Node { id: 9, name: \"/_operators.0/Softmax\", inputs: [4/0>], op: Softmax { axes: [1], quant_output_dt: None, exp: Libc }, outputs: [1,4,F32 ] }\n",
      "Found Input operation\n",
      "Model loaded in 7.492416ms\n",
      "Number of public inputs: 2\n",
      "Number of public outputs: 5\n",
      "Required domain size: 4096\n",
      "Constraint system domain size: 8192\n",
      "Using SRS size: 4096\n",
      "node.op_type:Input\n",
      "node.op_type:Const\n",
      "node:SerializableNode { inputs: [], out_dims: [2, 4], out_scale: 1, id: 1, op_type: Const, op_params: Some([-0.2899942, -0.41289154, 0.4130071, 0.28987864, -0.6468678, 0.06529999, -0.06524275, 0.6468106]), attributes: {} }\n",
      "node_idx:1\n",
      "node.op_type:EinSum\n",
      "node.op_type:Const\n",
      "node:SerializableNode { inputs: [], out_dims: [1, 4], out_scale: 1, id: 3, op_type: Const, op_params: Some([1.6625432, 0.5548876, -0.42277858, -1.7946522]), attributes: {} }\n",
      "node_idx:3\n",
      "node.op_type:Add\n",
      "node.op_type:ArgMax\n",
      "axes: [1]\n",
      "input_shape: [1, 4]\n",
      "node.op_type:RmAxis\n",
      "node.op_type:Const\n",
      "node:SerializableNode { inputs: [], out_dims: [4], out_scale: 1, id: 7, op_type: Const, op_params: Some([6.0, 8.0, 9.0, 11.0]), attributes: {} }\n",
      "node_idx:7\n",
      "node.op_type:Gather\n",
      "node.op_type:Softmax\n",
      "node.out_dims: [1, 4], inputs[0]: 4\n",
      "dbg\n",
      "result: [0.3843968, 0.5179047, 0.05392917, 0.043769334]\n",
      "Calculate space needed for operations node.out_dims: [1, 2]\n",
      "Calculate space needed for operations node.out_dims: [2, 4]\n",
      "Calculate space needed for operations node.out_dims: [1, 4]\n",
      "Calculate space needed for operations node.out_dims: [1, 4]\n",
      "Calculate space needed for operations node.out_dims: [1, 4]\n",
      "Calculate space needed for operations node.out_dims: [1, 1]\n",
      "Calculate space needed for operations node.out_dims: [1]\n",
      "Calculate space needed for operations node.out_dims: [4]\n",
      "Calculate space needed for operations node.out_dims: [1]\n",
      "Calculate space needed for operations node.out_dims: [1, 4]\n",
      "Proof generated and saved to \"proof.json\"\n",
      "\n",
      "Proof successfully generated at proof.json\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Paths for CLI commands\n",
    "proof_path = \"proof.json\"\n",
    "\n",
    "# Command for proof generation\n",
    "# Make sure to generate the binary first: `cargo build --release`\n",
    "cmd = [\n",
    "    \"/content/mina-zkml-cli\", \"proof\",\n",
    "    \"-m\", onnx_path,\n",
    "    \"-i\", data_path,\n",
    "    \"-o\", proof_path,\n",
    "    \"--input-visibility\", \"public\",\n",
    "    \"--output-visibility\", \"public\"\n",
    "]\n",
    "\n",
    "# Run the CLI command\n",
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "print(result.stdout)\n",
    "if result.returncode == 0:\n",
    "    print(f\"Proof successfully generated at {proof_path}\")\n",
    "else:\n",
    "    print(f\"Error generating proof: {result.stderr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269df498-6cab-4356-b664-cb6a63ff1f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output data successfully saved to output.json\n"
     ]
    }
   ],
   "source": [
    "# Extract the \"output\" field from proof.json\n",
    "output_path = \"output.json\"\n",
    "try:\n",
    "    with open(proof_path, \"r\") as proof_file:\n",
    "        proof_data = json.load(proof_file)\n",
    "    if \"output\" in proof_data:\n",
    "        output_data = proof_data[\"output\"]\n",
    "        with open(output_path, \"w\") as output_file:\n",
    "            json.dump(output_data, output_file, indent=4)\n",
    "        print(f\"Output data successfully saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"No 'output' field found in proof.json\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57ce4409-884c-434e-8d66-0adbf7f17d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output data successfully saved to output.json\n"
     ]
    }
   ],
   "source": [
    "# Create a public output file from the proof\n",
    "try:\n",
    "    # Load proof.json\n",
    "    with open(proof_path, \"r\") as proof_file:\n",
    "        proof_data = json.load(proof_file)\n",
    "\n",
    "    # Extract the \"output\" field\n",
    "    if \"output\" in proof_data:\n",
    "        output_data = proof_data[\"output\"]\n",
    "        \n",
    "        # Save the output data to output.json\n",
    "        with open(output_path, \"w\") as output_file:\n",
    "            json.dump(output_data, output_file, indent=4)\n",
    "        \n",
    "        print(f\"Output data successfully saved to {output_path}\")\n",
    "    else:\n",
    "        print(\"No 'output' field found in proof.json\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d4244b-210e-4bb2-ada0-8d212cf303d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: Node { id: 0, name: \"input\", inputs: [], op: TypedSource { fact: 1,2,F32 }, outputs: [1,2,F32 >2/0] }\n",
      "Found Input operation\n",
      "Node: Node { id: 1, name: \"_operators.0.coefficients.0\", inputs: [], op: Const(2,4,F32 -0.2899942, -0.41289154, 0.4130071, 0.28987864, -0.6468678, 0.06529999, -0.06524275, 0.6468106), outputs: [2,4,F32 -0.2899942, -0.41289154, 0.4130071, 0.28987864, -0.6468678, 0.06529999, -0.06524275, 0.6468106 >2/1] }\n",
      "Found Const operation\n",
      "Node: Node { id: 2, name: \"/_operators.0/Gemm.ab\", inputs: [0/0>, 1/0>], op: EinSum mk,kn->mn (F32), outputs: [1,4,F32 >4/0] }\n",
      "Found matrix operation: EinSum\n",
      "Node: Node { id: 3, name: \"/_operators.0/Gemm.c_add_axis_1\", inputs: [], op: Const(1,4,F32 1.6625432, 0.5548876, -0.42277858, -1.7946522), outputs: [1,4,F32 1.6625432, 0.5548876, -0.42277858, -1.7946522 >4/1] }\n",
      "Found Const operation\n",
      "Node: Node { id: 4, name: \"/_operators.0/Gemm\", inputs: [2/0>, 3/0>], op: TypedBinOp(Add, None), outputs: [1,4,F32 >5/0 >9/0] }\n",
      "Found Add operation: Add\n",
      "Node: Node { id: 5, name: \"/_operators.0/ArgMax\", inputs: [4/0>], op: Reduce { axes: [1], reducer: ArgMax(false) }, outputs: [1,1,I64 >6/0] }\n",
      "Found ArgMax operation\n",
      "Node: Node { id: 6, name: \"/_operators.0/ArgMax-dispose-dims-1\", inputs: [5/0>], op: Rm(1), outputs: [1,I64 >8/1] }\n",
      "Found RmAxis operation\n",
      "Node: Node { id: 7, name: \"_operators.0.classes.0\", inputs: [], op: Const(4,I32 6, 8, 9, 11), outputs: [4,I32 6, 8, 9, 11 >8/0] }\n",
      "Found Const operation\n",
      "Node: Node { id: 8, name: \"/_operators.0/Gather\", inputs: [7/0>, 6/0>], op: Gather { axis: 0 }, outputs: [1,I32 ] }\n",
      "Found Gather operation\n",
      "Node: Node { id: 9, name: \"/_operators.0/Softmax\", inputs: [4/0>], op: Softmax { axes: [1], quant_output_dt: None, exp: Libc }, outputs: [1,4,F32 ] }\n",
      "Found Input operation\n",
      "Model loaded in 783.917µs\n",
      "Number of public inputs: 2\n",
      "Number of public outputs: 5\n",
      "Required domain size: 4096\n",
      "Constraint system domain size: 8192\n",
      "Using SRS size: 4096\n",
      "Processing public inputs: [[1.0, 1.0]]\n",
      "Processing input 0: [1.0, 1.0]\n",
      "Converting input 0,0 = 1 to field: BigInt([1000000, 0, 0, 0])\n",
      "Converting input 0,1 = 1 to field: BigInt([1000000, 0, 0, 0])\n",
      "Processing public outputs: [[8.0], [0.3843968, 0.5179047, 0.05392917, 0.043769334]]\n",
      "Processing output 0: [8.0]\n",
      "Converting output 0,0 = 8 to field: BigInt([8000000, 0, 0, 0])\n",
      "Processing output 1: [0.3843968, 0.5179047, 0.05392917, 0.043769334]\n",
      "Converting output 1,0 = 0.3843968 to field: BigInt([384396, 0, 0, 0])\n",
      "Converting output 1,1 = 0.5179047 to field: BigInt([517904, 0, 0, 0])\n",
      "Converting output 1,2 = 0.05392917 to field: BigInt([53929, 0, 0, 0])\n",
      "Converting output 1,3 = 0.043769334 to field: BigInt([43769, 0, 0, 0])\n",
      "Verifying with 7 public values\n",
      "Proof verification successful\n",
      "✅ Proof verification successful!\n",
      "\n",
      "Model output:\n",
      "[\n",
      "  [\n",
      "    8.0\n",
      "  ],\n",
      "  [\n",
      "    0.3843968,\n",
      "    0.5179047,\n",
      "    0.05392917,\n",
      "    0.043769334\n",
      "  ]\n",
      "]\n",
      "\n",
      "Proof successfully verified at proof.json\n"
     ]
    }
   ],
   "source": [
    "# Command for proof verification\n",
    "cmd = [\n",
    "    \"/content/mina-zkml-cli\"\", \"verify\",\n",
    "    \"-m\", onnx_path,\n",
    "    \"-i\", data_path,\n",
    "    \"-p\", proof_path,\n",
    "    \"-o\", output_path,\n",
    "    \"--input-visibility\", \"public\",\n",
    "    \"--output-visibility\", \"public\"\n",
    "]\n",
    "\n",
    "# Run the CLI command\n",
    "result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "print(result.stdout)\n",
    "if result.returncode == 0:\n",
    "    print(f\"Proof successfully verified at {proof_path}\")\n",
    "else:\n",
    "    print(f\"Error verifying proof: {result.stderr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987fe13a",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "For deploying this model, in a Mina network, we need to follow the steps below:\n",
    "\n",
    "1. Clone `https://github.com/chris-chris/mina-zkml-verifier.git` repository.\n",
    "2. Move to the `mina-zkml-verifier` directory.\n",
    "3. Run `npm install` to install the dependencies.\n",
    "4. Follow the network setup instructions in the `README.md` file in the mina-zkml-verifier repository.\n",
    "5. Update the `modelConfig.json` file with the correct values, and the model in onnx format.\n",
    "6. Run `zk deploy <NETWORK_NAME>`, the <NETWORK_NAME> is alias for the account you created in step 4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
